{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Enter output filename\")\n",
    "# output = input()\n",
    "# print(\"Enter test data filename\")\n",
    "# file_name = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.read_csv(file_name)\n",
    "\n",
    "# # Drop variable\n",
    "# df = df.drop(columns=['open', 'high', 'low', 'close', 'volume', 'dividend', 'split'])\n",
    "\n",
    "# # Split data by IDs and write to different files\n",
    "# dfs = dict(tuple(df.groupby('id')))\n",
    "# list_df = [dfs[x] for x in dfs]\n",
    "# for index, df in enumerate(list_df):\n",
    "#     df['moving_average'] = df['adjusted_close'].rolling(5).mean()\n",
    "#     df.to_csv(\"data_by_id/\" + str(index) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "directory_in_str = os.getcwd()\n",
    "directory_in_str += '/data_by_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_category(now, week_from_now):\n",
    "    ratio = float(week_from_now)/now\n",
    "    percentile = (ratio - 1) * 100\n",
    "    if abs(percentile) >= 5:\n",
    "        return np.sign(percentile) * 3\n",
    "    elif abs(percentile) >= 3:\n",
    "        return np.sign(percentile) * 2\n",
    "    elif abs(percentile) >= 2:\n",
    "        return np.sign(percentile)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_predict(filename):\n",
    "    filename = filename # 'Just_1/' + \n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename, index_col=\"time\",parse_dates=True)\n",
    "    df = df[4:]\n",
    "    column = df['adjusted_open'].count()\n",
    "    if (column > 60):\n",
    "        return actual_predict(df, column)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_predict(df, column):\n",
    "        temp = df.copy()\n",
    "        training_set = df.drop(['id', 'adjusted_volume'], axis=1)\n",
    "        # Feature Scaling\n",
    "        sc = MinMaxScaler(feature_range = (0, 1))\n",
    "        training_set_scaled = sc.fit_transform(training_set)\n",
    "        training_set_scaled.shape\n",
    "        # Creating a data structure with 60 timesteps and 1 output\n",
    "        X_test = []\n",
    "        for i in range(60, column):\n",
    "            X_test.append(training_set_scaled[i-60:i, :])\n",
    "        X_test = np.array(X_test)\n",
    "        # Reshaping\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 5))\n",
    "        regressor = load_model('../model.h5')\n",
    "        y = regressor.predict(X_test)\n",
    "        return temp, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def change_percent(together_df):\n",
    "    together_df.rename(index=str, columns={3: \"price\"}, inplace = True)\n",
    "    together_df = together_df.assign(actual_lag_5 = lambda x: x.price.shift(-5))\n",
    "    together_df = together_df.assign(actual_percent = lambda x: (x.actual_lag_5 - x.price)/x.price)\n",
    "    together_df = together_df.assign(up_two = lambda x: (x.actual_percent > 0.02).astype(int))\n",
    "    together_df = together_df.assign(up_three = lambda x: (x.actual_percent > 0.03).astype(int))\n",
    "    together_df = together_df.assign(up_five = lambda x: (x.actual_percent > 0.05).astype(int))\n",
    "    \n",
    "    together_df = together_df.assign(down_two = lambda x: (x.actual_percent < 0.02).astype(int))\n",
    "    together_df = together_df.assign(down_three = lambda x: (x.actual_percent < 0.03).astype(int))\n",
    "    together_df = together_df.assign(down_five = lambda x: (x.actual_percent < 0.05).astype(int))\n",
    "    together_df = together_df.drop([0, 1, 2, 'price', 4, 'actual_lag_5', 'actual_percent'], axis=1)\n",
    "    return together_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(ids, y):\n",
    "    ids = ids.drop(['adjusted_close', 'adjusted_open', 'adjusted_high', 'adjusted_low', 'adjusted_volume', 'moving_average'], axis=1)\n",
    "    time_index = ids[60:].index\n",
    "    y.index = time_index\n",
    "    stock_id = ids.loc[ids.index[1],'id']\n",
    "    df_all_cols = pd.concat((ids[60:], y), axis = 1)\n",
    "    with open(\"../outputs/\" + str(stock_id) + \".txt\", \"a\") as myfile:\n",
    "        for i in df_all_cols.index:\n",
    "            if df_all_cols.loc[i,'up_two'] > 0 and df_all_cols.loc[i,'up_three'] > 0 and df_all_cols.loc[i,'up_five'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' +5 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            elif df_all_cols.loc[i,'up_two'] > 0 and df_all_cols.loc[i,'up_three'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' +3 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            elif df_all_cols.loc[i,'up_two'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' +2 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            elif df_all_cols.loc[i,'down_two'] > 0 and df_all_cols.loc[i,'down_three'] > 0 and df_all_cols.loc[i,'down_five'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' -5 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            elif df_all_cols.loc[i,'down_two'] > 0 and df_all_cols.loc[i,'down_three'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' -3 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            elif df_all_cols.loc[i,'down_two'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' -2 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            else:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' +0 \\n' )\n",
    "                myfile.write(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545.csv\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "223.csv\n",
      "4817.csv\n",
      "4803.csv\n",
      "237.csv\n",
      "6972.csv\n",
      "8787.csv\n",
      "9499.csv\n",
      "11395.csv\n",
      "6782.csv\n",
      "579.csv\n",
      "8977.csv\n",
      "3822.csv\n",
      "4195.csv\n",
      "2282.csv\n",
      "1953.csv\n",
      "1947.csv\n",
      "3188.csv\n",
      "2296.csv\n",
      "4181.csv\n",
      "6796.csv\n",
      "8963.csv\n",
      "8988.csv\n",
      "586.csv\n",
      "1012.csv\n",
      "8750.csv\n",
      "3605.csv\n",
      "11342.csv\n",
      "5274.csv\n",
      "5512.csv\n",
      "3163.csv\n",
      "11424.csv\n",
      "1774.csv\n",
      "9328.csv\n",
      "7311.csv\n",
      "8022.csv\n",
      "1760.csv\n",
      "2269.csv\n",
      "3177.csv\n",
      "11430.csv\n",
      "4618.csv\n",
      "3611.csv\n",
      "5260.csv\n",
      "8744.csv\n",
      "4156.csv\n",
      "3639.csv\n",
      "10060.csv\n",
      "2527.csv\n",
      "5248.csv\n",
      "9472.csv\n",
      "6741.csv\n",
      "1990.csv\n",
      "7339.csv\n",
      "1748.csv\n",
      "9314.csv\n",
      "10706.csv\n",
      "2241.csv\n",
      "11418.csv\n",
      "4630.csv\n",
      "10712.csv\n",
      "2255.csv\n",
      "4624.csv\n",
      "9300.csv\n",
      "6033.csv\n",
      "9466.csv\n",
      "8778.csv\n",
      "10074.csv\n",
      "2533.csv\n",
      "747.csv\n",
      "8591.csv\n",
      "2902.csv\n",
      "2916.csv\n",
      "10289.csv\n",
      "753.csv\n",
      "9843.csv\n",
      "1589.csv\n",
      "2080.csv\n",
      "5937.csv\n",
      "4397.csv\n",
      "5089.csv\n",
      "7846.csv\n",
      "6580.csv\n",
      "7852.csv\n",
      "6594.csv\n",
      "4383.csv\n",
      "5923.csv\n",
      "6219.csv\n",
      "1576.csv\n",
      "7107.csv\n",
      "10538.csv\n",
      "5076.csv\n",
      "2719.csv\n",
      "3407.csv\n",
      "4368.csv\n",
      "8552.csv\n",
      "9894.csv\n",
      "1210.csv\n",
      "784.csv\n",
      "948.csv\n",
      "9880.csv\n",
      "790.csv\n",
      "1204.csv\n",
      "3413.csv\n",
      "5704.csv\n",
      "1562.csv\n",
      "7113.csv\n",
      "4432.csv\n",
      "6225.csv\n",
      "9116.csv\n",
      "960.csv\n",
      "7885.csv\n",
      "6543.csv\n",
      "9670.csv\n",
      "2725.csv\n",
      "11168.csv\n",
      "4340.csv\n",
      "7649.csv\n",
      "974.csv\n",
      "7891.csv\n",
      "1238.csv\n",
      "9664.csv\n",
      "6231.csv\n",
      "9102.csv\n",
      "4426.csv\n",
      "3349.csv\n",
      "2057.csv\n",
      "10510.csv\n",
      "155.csv\n",
      "8383.csv\n",
      "9923.csv\n",
      "2876.csv\n",
      "2862.csv\n",
      "9937.csv\n",
      "141.csv\n",
      "9089.csv\n",
      "169.csv\n",
      "5843.csv\n",
      "2692.csv\n",
      "97.csv\n",
      "7932.csv\n",
      "83.csv\n",
      "2686.csv\n",
      "5857.csv\n",
      "4591.csv\n",
      "6386.csv\n",
      "196.csv\n",
      "5664.csv\n",
      "3215.csv\n",
      "3573.csv\n",
      "5102.csv\n",
      "9738.csv\n",
      "68.csv\n",
      "1364.csv\n",
      "8426.csv\n",
      "7715.csv\n",
      "1370.csv\n",
      "8432.csv\n",
      "7701.csv\n",
      "4208.csv\n",
      "3567.csv\n",
      "5116.csv\n",
      "5670.csv\n",
      "3201.csv\n",
      "8354.csv\n",
      "7067.csv\n",
      "182.csv\n",
      "1416.csv\n",
      "6379.csv\n",
      "5658.csv\n",
      "2137.csv\n",
      "10470.csv\n",
      "3229.csv\n",
      "4546.csv\n",
      "9062.csv\n",
      "54.csv\n",
      "9704.csv\n",
      "7729.csv\n",
      "814.csv\n",
      "2889.csv\n",
      "4220.csv\n",
      "2651.csv\n",
      "10316.csv\n",
      "4234.csv\n",
      "2645.csv\n",
      "40.csv\n",
      "6423.csv\n",
      "9710.csv\n",
      "800.csv\n",
      "8368.csv\n",
      "2123.csv\n",
      "10464.csv\n",
      "4552.csv\n",
      "431.csv\n",
      "6812.csv\n",
      "8181.csv\n",
      "357.csv\n",
      "4963.csv\n",
      "8195.csv\n",
      "343.csv\n",
      "8803.csv\n",
      "3956.csv\n",
      "2490.csv\n",
      "4787.csv\n",
      "1827.csv\n",
      "6190.csv\n",
      "1833.csv\n",
      "3942.csv\n",
      "419.csv\n",
      "8817.csv\n",
      "7517.csv\n",
      "8624.csv\n",
      "1166.csv\n",
      "5300.csv\n",
      "10128.csv\n",
      "3771.csv\n",
      "3017.csv\n",
      "2309.csv\n",
      "1600.csv\n",
      "7271.csv\n",
      "8142.csv\n",
      "380.csv\n",
      "8156.csv\n",
      "3003.csv\n",
      "5472.csv\n",
      "5314.csv\n",
      "7503.csv\n",
      "8630.csv\n",
      "1172.csv\n",
      "3995.csv\n",
      "10114.csv\n",
      "2453.csv\n",
      "4022.csv\n",
      "8618.csv\n",
      "9506.csv\n",
      "6635.csv\n",
      "9260.csv\n",
      "6153.csv\n",
      "4744.csv\n",
      "2335.csv\n",
      "4750.csv\n",
      "4988.csv\n",
      "10666.csv\n",
      "2321.csv\n",
      "9274.csv\n",
      "6147.csv\n",
      "1628.csv\n",
      "7259.csv\n",
      "9512.csv\n",
      "6621.csv\n",
      "5328.csv\n",
      "3981.csv\n",
      "10100.csv\n",
      "2447.csv\n",
      "3759.csv\n",
      "7258.csv\n",
      "1629.csv\n",
      "6146.csv\n",
      "9275.csv\n",
      "2320.csv\n",
      "4989.csv\n",
      "10667.csv\n",
      "4751.csv\n",
      "3758.csv\n",
      "2446.csv\n",
      "10101.csv\n",
      "3980.csv\n",
      "5329.csv\n",
      "6620.csv\n",
      "6634.csv\n",
      "9507.csv\n",
      "8619.csv\n",
      "4023.csv\n",
      "2452.csv\n",
      "10115.csv\n",
      "3994.csv\n",
      "2334.csv\n",
      "6152.csv\n",
      "9261.csv\n",
      "5473.csv\n",
      "3002.csv\n",
      "7264.csv\n",
      "381.csv\n",
      "1615.csv\n",
      "8631.csv\n",
      "7502.csv\n",
      "3764.csv\n",
      "3770.csv\n",
      "10129.csv\n",
      "5301.csv\n",
      "6608.csv\n",
      "7516.csv\n",
      "1601.csv\n",
      "395.csv\n",
      "5467.csv\n",
      "2308.csv\n",
      "3016.csv\n",
      "4779.csv\n",
      "4792.csv\n",
      "6185.csv\n",
      "1832.csv\n",
      "418.csv\n",
      "8816.csv\n",
      "3943.csv\n",
      "2491.csv\n",
      "8802.csv\n",
      "6191.csv\n",
      "1826.csv\n",
      "4786.csv\n",
      "5498.csv\n",
      "342.csv\n",
      "6807.csv\n",
      "424.csv\n",
      "6813.csv\n",
      "430.csv\n",
      "4962.csv\n",
      "356.csv\n",
      "8180.csv\n",
      "6422.csv\n",
      "10303.csv\n",
      "2644.csv\n",
      "4553.csv\n",
      "10465.csv\n",
      "2122.csv\n",
      "8369.csv\n",
      "9063.csv\n",
      "6350.csv\n",
      "7.csv\n",
      "3228.csv\n",
      "10471.csv\n",
      "2136.csv\n",
      "10317.csv\n",
      "2650.csv\n",
      "4221.csv\n",
      "2888.csv\n",
      "815.csv\n",
      "7728.csv\n",
      "1359.csv\n",
      "9705.csv\n",
      "55.csv\n",
      "5117.csv\n",
      "2678.csv\n",
      "3566.csv\n",
      "4209.csv\n",
      "7700.csv\n",
      "8433.csv\n",
      "1371.csv\n",
      "6378.csv\n",
      "1417.csv\n",
      "7066.csv\n",
      "8355.csv\n",
      "3200.csv\n",
      "5671.csv\n",
      "3214.csv\n",
      "5665.csv\n",
      "197.csv\n",
      "1403.csv\n",
      "8341.csv\n",
      "7714.csv\n",
      "8427.csv\n",
      "829.csv\n",
      "1365.csv\n",
      "69.csv\n",
      "9739.csv\n",
      "5103.csv\n",
      "3572.csv\n",
      "3599.csv\n",
      "2687.csv\n",
      "7927.csv\n",
      "6387.csv\n",
      "5856.csv\n",
      "4584.csv\n",
      "5842.csv\n",
      "6393.csv\n",
      "168.csv\n",
      "96.csv\n",
      "2693.csv\n",
      "9936.csv\n",
      "2863.csv\n",
      "8396.csv\n",
      "140.csv\n",
      "8382.csv\n",
      "154.csv\n",
      "2877.csv\n",
      "9922.csv\n",
      "9665.csv\n",
      "1239.csv\n",
      "7890.csv\n",
      "975.csv\n",
      "7648.csv\n",
      "10277.csv\n",
      "10511.csv\n",
      "2056.csv\n",
      "4427.csv\n",
      "6230.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f797776ccec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     print(filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mdfnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ded1f2b09449>\u001b[0m in \u001b[0;36mLSTM_predict\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjusted_open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mactual_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-253ace531f30>\u001b[0m in \u001b[0;36mactual_predict\u001b[0;34m(df, column)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Reshaping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    285\u001b[0m                              ' elements.')\n\u001b[1;32m    286\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 199\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('data_by_id')\n",
    "# directory = os.fsencode(directory_in_str)\n",
    "directory = os.getcwd()\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "#     print(filename)\n",
    "    if filename.endswith(\".csv\"):\n",
    "        temp, y = LSTM_predict(filename)\n",
    "        if y is not None:\n",
    "            dfnew = pd.DataFrame(y)\n",
    "            new = change_percent(dfnew)\n",
    "            write_to_file(temp, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('..')\n",
    "# os.chdir('data_by_id')\n",
    "print(os.getcwd())\n",
    "# directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = '../output/' + str(id) + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stock_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_id = dataset.loc[dataset.index[1],'id']\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
