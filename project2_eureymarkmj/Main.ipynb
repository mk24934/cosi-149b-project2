{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Enter output filename\")\n",
    "# output = input()\n",
    "# print(\"Enter test data filename\")\n",
    "# file_name = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.read_csv(file_name)\n",
    "\n",
    "# # Drop variable\n",
    "# df = df.drop(columns=['open', 'high', 'low', 'close', 'volume', 'dividend', 'split'])\n",
    "\n",
    "# # Split data by IDs and write to different files\n",
    "# dfs = dict(tuple(df.groupby('id')))\n",
    "# list_df = [dfs[x] for x in dfs]\n",
    "# for index, df in enumerate(list_df):\n",
    "#     df['moving_average'] = df['adjusted_close'].rolling(5).mean()\n",
    "#     df.to_csv(\"data_by_id/\" + str(index) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "directory_in_str = os.getcwd()\n",
    "directory_in_str += '/data_by_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_category(now, week_from_now):\n",
    "    ratio = float(week_from_now)/now\n",
    "    percentile = (ratio - 1) * 100\n",
    "    if abs(percentile) >= 5:\n",
    "        return np.sign(percentile) * 3\n",
    "    elif abs(percentile) >= 3:\n",
    "        return np.sign(percentile) * 2\n",
    "    elif abs(percentile) >= 2:\n",
    "        return np.sign(percentile)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_predict(filename):\n",
    "    filename = filename # 'Just_1/' + \n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename, index_col=\"time\",parse_dates=True)\n",
    "    df = df[4:]\n",
    "    column = df['adjusted_open'].count()\n",
    "    if (column > 60):\n",
    "        return actual_predict(df, column)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_predict(df, column):\n",
    "        temp = df.copy()\n",
    "        training_set = df.drop(['id', 'adjusted_volume'], axis=1)\n",
    "        # Feature Scaling\n",
    "        sc = MinMaxScaler(feature_range = (0, 1))\n",
    "        training_set_scaled = sc.fit_transform(training_set)\n",
    "        training_set_scaled.shape\n",
    "        # Creating a data structure with 60 timesteps and 1 output\n",
    "        X_test = []\n",
    "        for i in range(column - 125, column):\n",
    "            X_test.append(training_set_scaled[i-60:i, :])\n",
    "        X_test = np.array(X_test)\n",
    "        # Reshaping\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 6))\n",
    "        regressor = load_model('../model.h5')\n",
    "        y = regressor.predict(X_test)\n",
    "        return temp, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " def change_percent(together_df):\n",
    "    together_df.rename(index=str, columns={3: \"price\"}, inplace = True)\n",
    "    together_df = together_df.assign(actual_lag_5 = lambda x: x.price.shift(-5))\n",
    "    together_df = together_df.assign(actual_percent = lambda x: (x.actual_lag_5 - x.price)/x.price)\n",
    "    together_df = together_df.assign(up_two = lambda x: (x.actual_percent > 0.02).astype(int))\n",
    "    together_df = together_df.assign(up_three = lambda x: (x.actual_percent > 0.03).astype(int))\n",
    "    together_df = together_df.assign(up_five = lambda x: (x.actual_percent > 0.05).astype(int))\n",
    "    \n",
    "    together_df = together_df.assign(down_two = lambda x: (x.actual_percent < -0.02).astype(int))\n",
    "    together_df = together_df.assign(down_three = lambda x: (x.actual_percent < -0.03).astype(int))\n",
    "    together_df = together_df.assign(down_five = lambda x: (x.actual_percent < -0.05).astype(int))\n",
    "    together_df = together_df.drop([0, 1, 2, 'price', 4, 'actual_lag_5', 'actual_percent'], axis=1)\n",
    "    return together_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(ids, y):\n",
    "    ids = ids.drop(['adjusted_close', 'adjusted_open', 'adjusted_high', 'adjusted_low', 'adjusted_volume', 'moving_average'], axis=1)\n",
    "    n = ids.shape[0]\n",
    "    time_index = ids[n - 125:].index # ids[60:].index\n",
    "    y.index = time_index\n",
    "    stock_id = ids.loc[ids.index[1],'id']\n",
    "    df_all_cols = pd.concat((ids[60:], y), axis = 1)\n",
    "    with open(\"../outputs/\" + str(stock_id) + \".txt\", \"a\") as myfile:\n",
    "        for i in df_all_cols.index:\n",
    "            if df_all_cols.loc[i,'up_two'] > 0 and df_all_cols.loc[i,'up_three'] > 0 and df_all_cols.loc[i,'up_five'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' +5 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            elif df_all_cols.loc[i,'up_two'] > 0 and df_all_cols.loc[i,'up_three'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' +3 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            elif df_all_cols.loc[i,'up_two'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' +2 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            elif df_all_cols.loc[i,'down_two'] > 0 and df_all_cols.loc[i,'down_three'] > 0 and df_all_cols.loc[i,'down_five'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' -5 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            elif df_all_cols.loc[i,'down_two'] > 0 and df_all_cols.loc[i,'down_three'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' -3 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            elif df_all_cols.loc[i,'down_two'] > 0:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' -2 \\n' )\n",
    "                myfile.write(new_line)\n",
    "            else:\n",
    "                new_line = str(str(stock_id) + ' ' + str(i) + ' +0 \\n' )\n",
    "                myfile.write(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 37500 into shape (125,60,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e6285d819e98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     print(filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mdfnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ded1f2b09449>\u001b[0m in \u001b[0;36mLSTM_predict\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjusted_open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mactual_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-af331df96cdf>\u001b[0m in \u001b[0;36mactual_predict\u001b[0;34m(df, column)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Reshaping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    290\u001b[0m            [5, 6]])\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 37500 into shape (125,60,1)"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('Just_1') # os.chdir('data_by_id')\n",
    "# directory = os.fsencode(directory_in_str)\n",
    "directory = os.getcwd()\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "#     print(filename)\n",
    "    if filename.endswith(\".csv\"):\n",
    "        temp, y = LSTM_predict(filename)\n",
    "        if y is not None:\n",
    "            dfnew = pd.DataFrame(y)\n",
    "            print(dfnew)\n",
    "            new = change_percent(dfnew)\n",
    "            print(new)\n",
    "#             write_to_file(temp, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('..')\n",
    "# os.chdir('data_by_id')\n",
    "print(os.getcwd())\n",
    "# directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = '../output/' + str(id) + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stock_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_id = dataset.loc[dataset.index[1],'id']\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
